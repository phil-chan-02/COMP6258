{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "labex7-seq2seq.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phil-chan-02/COMP6258/blob/main/labex7_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1lc3xnYPSlw"
      },
      "source": [
        "First we import libraries and set the random seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJXe-HNwOvWq"
      },
      "source": [
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "from tqdm.autonotebook import tqdm\n",
        "from textwrap import wrap\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvgBTudyPamX"
      },
      "source": [
        "The following block defines a dataset object which parses our data file and performs numericalisation of the sequence data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obU0x4DzO2ce"
      },
      "source": [
        "class CodeDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        download_url('https://github.com/ecs-vlc/COMP6248/raw/master/exercises/lab7/dataset.txt', '.', 'dataset.txt', None)\n",
        "        with io.open('dataset.txt', 'r') as f:\n",
        "            self.data = f.readlines()\n",
        "\n",
        "        self.PAD='_'\n",
        "        self.SOS='^'\n",
        "        self.EOS='$'\n",
        "        self.PAD_IDX=0\n",
        "\n",
        "        # construct the vocabularies to numericalise the data\n",
        "        self.alphabet = \"*\".join(self.PAD+self.SOS+self.EOS+\"abcdefghijklmnopqrstuvwxyz \").split('*')\n",
        "\n",
        "        self.alphabet_indices = dict((c, i) for i, c in enumerate(self.alphabet))\n",
        "        self.indices_alphabet = dict((i, c) for i, c in enumerate(self.alphabet))\n",
        "\n",
        "        self.morsebet = self.PAD+self.SOS+self.EOS+'.- /'\n",
        "        self.morse_indices = dict((c, i) for i, c in enumerate(self.morsebet))\n",
        "        self.indices_morse = dict((i, c) for i, c in enumerate(self.morsebet))\n",
        "\n",
        "    def encode_alpha(self, inp):\n",
        "        x = torch.zeros(len(inp), dtype=torch.long)\n",
        "        for t, char in enumerate(inp):\n",
        "            x[t] = self.alphabet_indices[char]\n",
        "\n",
        "        return x\n",
        "\n",
        "    def decode_alpha(self, ten, skip_tok=False):\n",
        "        s = ''\n",
        "        ten = ten.view(-1)\n",
        "        for v in ten.view(-1):\n",
        "            if not skip_tok:\n",
        "                s += self.indices_alphabet[v.item()]\n",
        "            elif v>2:\n",
        "                s += self.indices_alphabet[v.item()]\n",
        "        return s\n",
        "\n",
        "    def encode_morse(self, inp):\n",
        "        x = torch.zeros(len(inp), dtype=torch.long)\n",
        "        for t, char in enumerate(inp):\n",
        "            x[t] = self.morse_indices[char]\n",
        "\n",
        "        return x\n",
        "\n",
        "    def decode_morse(self, ten):\n",
        "        s = ''\n",
        "        for v in ten:\n",
        "          s += self.indices_morse[v]\n",
        "        return s\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        inp, out = self.data[i].strip().split('|')\n",
        "        x = self.encode_morse(inp)\n",
        "        y = self.encode_alpha(out[::-1])\n",
        "        return x, y\n",
        "\n",
        "\n",
        "# This will be used to automatically pad all batch items to the same length\n",
        "def pad_collate(batch):\n",
        "    data = [item[0] for item in batch]\n",
        "    data = pad_sequence(data)\n",
        "    targets = [item[1] for item in batch]\n",
        "    targets = pad_sequence(targets)\n",
        "    return [data, targets]\n",
        "\n",
        "# Load the data and split randomly into training and val subsets\n",
        "ds = CodeDataset()\n",
        "tr, va = random_split(ds, [len(ds) - len(ds)//3, len(ds)//3])\n",
        "trainloader = DataLoader(tr, batch_size=1024, shuffle=True, collate_fn=pad_collate)\n",
        "valloader = DataLoader(va, batch_size=1024, shuffle=False, collate_fn=pad_collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Fs_h2PPqWa"
      },
      "source": [
        "We next define the model architecture, which is made up of an encoder, a decoder and the Seq2Seq class which ties everything together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JxbT3pFO9Em"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # TODO\n",
        "        h0 = torch.zeros(src.size(1), self.hid_dim).cuda()\n",
        "        c0 = torch.zeros(src.size(1), self.hid_dim).cuda()\n",
        "        embedded = self.embedding(src)\n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.embedding(input)\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg=None, teacher_forcing_ratio = 0.5, maxlen=5, padding_idx=0):\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0] if trg is not None else maxlen\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(src.device)\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        input = torch.ones(batch_size, dtype=torch.long, device=src.device) * padding_idx\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force and trg is not None else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIM = len(ds.morsebet)\n",
        "OUTPUT_DIM = len(ds.alphabet)\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM)\n",
        "model = Seq2Seq(enc, dec).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY4Y5DPVP7Ih"
      },
      "source": [
        "Finally, we can train and evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAkkOs_tPC68"
      },
      "source": [
        "crit = nn.CrossEntropyLoss(ignore_index=ds.PAD_IDX)\n",
        "opt = optim.Adam(model.parameters())\n",
        "\n",
        "for e in range(10):\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(trainloader), desc='train') as t:\n",
        "        epoch_loss = 0\n",
        "        for i, (x, y) in enumerate(trainloader):\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "            opt.zero_grad()\n",
        "            pred = model(x, y, padding_idx=ds.PAD_IDX)\n",
        "\n",
        "            pred_dim = pred.shape[-1]\n",
        "            pred = pred[1:].view(-1, pred_dim)\n",
        "            y = y[1:].view(-1)\n",
        "\n",
        "            loss = crit(pred, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            epoch_loss = (epoch_loss*i + loss.item()) / (i+1)\n",
        "\n",
        "            t.set_postfix(loss='{:05.3f}'.format(epoch_loss))\n",
        "            t.update()\n",
        "\n",
        "    model.eval()\n",
        "    with tqdm(total=len(valloader), desc='val') as t:\n",
        "        with torch.no_grad():\n",
        "            epoch_loss = 0\n",
        "            for i, (x, y) in enumerate(valloader):\n",
        "                x = x.cuda()\n",
        "                y = y.cuda()\n",
        "\n",
        "                pred = model(x, y, teacher_forcing_ratio=0, padding_idx=ds.PAD_IDX)\n",
        "\n",
        "                pred_dim = pred.shape[-1]\n",
        "                pred = pred[1:].view(-1, pred_dim)\n",
        "                y = y[1:].view(-1)\n",
        "\n",
        "                loss = crit(pred, y)\n",
        "                epoch_loss = (epoch_loss*i + loss.item()) / (i+1)\n",
        "\n",
        "                t.set_postfix(loss='{:05.3f}'.format(epoch_loss))\n",
        "                t.update()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EjXSAOUPFfE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}